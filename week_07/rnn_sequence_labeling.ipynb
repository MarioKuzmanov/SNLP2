{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### In Colab"
   ],
   "metadata": {
    "id": "xCaU4w3KH2xS"
   },
   "id": "xCaU4w3KH2xS"
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('drive', force_remount=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8ScFPCnp_aq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750507634750,
     "user_tz": -120,
     "elapsed": 22671,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    },
    "outputId": "c283dc47-1453-4ca2-b5f9-2171c28e2104"
   },
   "id": "k8ScFPCnp_aq",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install seqeval"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3tpbjn4p89X",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750507643523,
     "user_tz": -120,
     "elapsed": 8774,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    },
    "outputId": "0163c86a-26b8-491a-f0ef-0895584f4f49"
   },
   "id": "c3tpbjn4p89X",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/43.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.6/43.6 kB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (2.0.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=5b9e112bb2fc280011ba7d2afb1c14a2b9c2c50052e49334e5ae5cd50873e4ab\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "id": "bf7gHfh1H6lF"
   },
   "id": "bf7gHfh1H6lF"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from seqeval.metrics import f1_score\n",
    "from copy import deepcopy\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T17:30:11.001466Z",
     "start_time": "2025-06-15T17:30:10.944089Z"
    },
    "id": "f65f5f9864788910"
   },
   "id": "f65f5f9864788910",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read Dataset"
   ],
   "metadata": {
    "id": "ixkZ5ojNH9Kb"
   },
   "id": "ixkZ5ojNH9Kb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data documents: 1312\n",
      "sent: ['analysis', 'of', 'the', 'efficacy', 'of', 'diet', 'and', 'short-term', 'probiotic', 'intervention', 'on', 'depressive', 'symptoms', 'in', 'patients', 'after', 'bariatric', 'surgery', ':', 'a', 'randomized', 'double-blind', 'placebo', 'controlled', 'pilot', 'study', '.']\n",
      "labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DDF', 'I-DDF', 'O', 'B-human', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "with open('data/all_data.data', 'rt', encoding='utf8') as fr:\n",
    "    all_data = fr.read().split('\\n')\n",
    "    all_labels = set()\n",
    "\n",
    "    X, Y, xx, yy = [], [], [], []\n",
    "    for line in all_data:\n",
    "        if line.strip():\n",
    "            w, label, _, _, _, _ = line.split('\\t')\n",
    "            all_labels.add(label)\n",
    "            xx.append(w.lower())\n",
    "            yy.append(label)\n",
    "        else:\n",
    "            X.append(xx.copy())\n",
    "            Y.append(yy.copy())\n",
    "            xx.clear()\n",
    "            yy.clear()\n",
    "\n",
    "assert len(X) == len(Y)\n",
    "\n",
    "print(f'data documents: {len(X)}\\n'\n",
    "      f'sent: {X[0]}\\n'\n",
    "      f'labels: {Y[0]}')"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T17:30:11.279101Z",
     "start_time": "2025-06-15T17:30:11.238302Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b289649cd2b0328c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750508424339,
     "user_tz": -120,
     "elapsed": 57,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    },
    "outputId": "3fbe55bf-6df2-43b9-da71-df83f4e9ffa9"
   },
   "id": "b289649cd2b0328c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "labels: (27, {'B-dietary%supplement', 'I-food', 'B-statistical%technique', 'O', 'I-bacteria', 'B-DDF', 'B-bacteria', 'I-chemical', 'B-microbiome', 'I-DDF', 'I-biomedical%technique', 'B-anatomical%location', 'I-animal', 'B-drug', 'I-drug', 'B-human', 'I-statistical%technique', 'B-biomedical%technique', 'B-food', 'B-animal', 'I-gene', 'I-dietary%supplement', 'B-gene', 'I-human', 'I-anatomical%location', 'B-chemical', 'I-microbiome'})\n"
     ]
    }
   ],
   "source": [
    "print(f'labels: {len(all_labels), all_labels}')"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T17:30:12.365087Z",
     "start_time": "2025-06-15T17:30:12.360024Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "721da67e7ab8d753",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750508432077,
     "user_tz": -120,
     "elapsed": 20,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    },
    "outputId": "7ebda08e-f66b-4261-ebc3-bfea03e468a2"
   },
   "id": "721da67e7ab8d753",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "label2id = {label: i for i, label in enumerate(list(all_labels))}\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T17:30:12.599465Z",
     "start_time": "2025-06-15T17:30:12.595361Z"
    },
    "id": "1a8bc580a5a2b7e3"
   },
   "id": "1a8bc580a5a2b7e3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split into Train and Test"
   ],
   "metadata": {
    "id": "D18UqPc3ICrf"
   },
   "id": "D18UqPc3ICrf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "944 263 105\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=.1, random_state=42)\n",
    "\n",
    "print(len(X_train), len(X_test), len(X_val))"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T17:30:12.770591Z",
     "start_time": "2025-06-15T17:30:12.762578Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86253a22f6716107",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750508435798,
     "user_tz": -120,
     "elapsed": 21,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    },
    "outputId": "33e85304-ebb9-46cc-9106-b177b3299689"
   },
   "id": "86253a22f6716107",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "size of vocab: 3984\n"
     ]
    }
   ],
   "source": [
    "vocab = ['<UNK>', '<PAD>'] + sorted({w for w in X_train for w in w})\n",
    "vocab2id = {w: i for i, w in enumerate(vocab)}\n",
    "id2vocab = {v: k for k, v in vocab2id.items()}\n",
    "\n",
    "print(f'size of vocab: {len(vocab)}')"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T17:30:13.247858Z",
     "start_time": "2025-06-15T17:30:13.235955Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ac97e11fcec016b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750508436540,
     "user_tz": -120,
     "elapsed": 24,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    },
    "outputId": "f715d5f7-3f3e-46eb-a181-b2a5356eb851"
   },
   "id": "2ac97e11fcec016b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encode the input"
   ],
   "metadata": {
    "collapsed": false,
    "id": "c982a1caa3f48fa0"
   },
   "id": "c982a1caa3f48fa0"
  },
  {
   "cell_type": "code",
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, X, Y, vocab2id, label2id, max_seq_length):\n",
    "        self.X, self.Y = X, Y\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.vocab2id = vocab2id\n",
    "        self.label2id = label2id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens, labels = self.X[idx], self.Y[idx]\n",
    "\n",
    "        if len(tokens) > self.max_seq_length:\n",
    "            tokens = tokens[: self.max_seq_length]\n",
    "            labels = labels[: self.max_seq_length]\n",
    "        else:\n",
    "            tokens = tokens + ['<PAD>'] * (self.max_seq_length - len(tokens))\n",
    "            labels = labels + ['O'] * (self.max_seq_length - len(labels))\n",
    "\n",
    "        tokens_tensor = torch.tensor(\n",
    "            [self.vocab2id.get(token, self.vocab2id['<UNK>']) for token in tokens]).to(device)\n",
    "        labels_tensor = torch.tensor([self.label2id.get(label) for label in labels]).to(device)\n",
    "        return tokens_tensor, labels_tensor\n"
   ],
   "metadata": {
    "id": "pxdy7z3BDUZv"
   },
   "id": "pxdy7z3BDUZv",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Datasets"
   ],
   "metadata": {
    "id": "kNMHvFu2Y7xu"
   },
   "id": "kNMHvFu2Y7xu"
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = NERDataset(X=X_train, Y=Y_train, vocab2id=vocab2id, label2id=label2id, max_seq_length=256)\n",
    "val_dataset = NERDataset(X=X_val, Y=Y_val, vocab2id=vocab2id, label2id=label2id, max_seq_length=256)\n",
    "test_dataset = NERDataset(X=X_test, Y=Y_test, vocab2id=vocab2id, label2id=label2id, max_seq_length=256)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ],
   "metadata": {
    "id": "gkQi2mf6Y7e0"
   },
   "id": "gkQi2mf6Y7e0",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save Datasets\n",
    "\n",
    "- we do not want to process the same data many times, especially if it is larger"
   ],
   "metadata": {
    "id": "RBj0VRGiZAYb"
   },
   "id": "RBj0VRGiZAYb"
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save({'train': train_loader, 'val': val_loader, 'test': test_loader, 'vocab2id': vocab2id, 'id2vocab': id2vocab, 'label2id':label2id, 'id2label':id2label},\n",
    "           'data/loaders.pt')"
   ],
   "metadata": {
    "id": "p-xJBEreNp2r"
   },
   "id": "p-xJBEreNp2r",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LSTM Network"
   ],
   "metadata": {
    "id": "dOoEyIxMIK-x"
   },
   "id": "dOoEyIxMIK-x"
  },
  {
   "cell_type": "code",
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, output_size, bidirectional, num_layers):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, bidirectional=bidirectional, num_layers=num_layers, batch_first=True)\n",
    "        self.clf1 = nn.Linear(hidden_size * self.num_directions, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        e = self.embedding(X)\n",
    "        h0 = torch.zeros(self.num_directions * self.num_layers, X.shape[0], self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_directions * self.num_layers, X.shape[0], self.hidden_size).to(device)\n",
    "        o, (h0,c0) = self.lstm(e, (h0,c0))\n",
    "\n",
    "        return self.clf1(o)"
   ],
   "metadata": {
    "id": "JK26poz8QnDp"
   },
   "id": "JK26poz8QnDp",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GRU Network"
   ],
   "metadata": {
    "id": "Ki0Gt99IaTj-"
   },
   "id": "Ki0Gt99IaTj-"
  },
  {
   "cell_type": "code",
   "source": [
    "class MyGRU(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, output_size, bidirectional, num_layers):\n",
    "        super(MyGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, bidirectional=bidirectional, num_layers=num_layers, batch_first=True)\n",
    "        self.clf1 = nn.Linear(hidden_size * self.num_directions, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        e = self.embedding(X)\n",
    "        h0 = torch.zeros(self.num_directions * self.num_layers, X.shape[0], self.hidden_size).to(device)\n",
    "        # o contains all hidden states, h0 will be the final hidden state\n",
    "        o, h0 = self.gru(e, h0)\n",
    "        # if self.bidirectional:\n",
    "        #     # sum or concatenate the two directions\n",
    "        #     # be careful, if you decide to concatenate you will need to match the dimensions of the Linear Layer\n",
    "        #     # or leave it as it is and multiply hidden_size * 2\n",
    "        #     forward = o[:, : o.shape[1] // 2]\n",
    "        #     backward = o[:, o.shape[1] // 2:]\n",
    "        #     o = forward + backward\n",
    "        return self.clf1(o)"
   ],
   "metadata": {
    "id": "m58Z-9WqaHqG"
   },
   "id": "m58Z-9WqaHqG",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Initialization, Loss Function, Optimizer, Hyperparameters"
   ],
   "metadata": {
    "id": "fXtl2HPDZKZj"
   },
   "id": "fXtl2HPDZKZj"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T17:32:15.926575Z",
     "start_time": "2025-06-15T17:32:12.785621Z"
    },
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "input_size = len(vocab2id)\n",
    "emb_size = 1024\n",
    "hidden_size = 2 * emb_size\n",
    "output_size = len(label2id)\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "bidirectional = True\n",
    "num_layers = 2\n",
    "model_name = 'lstm-2-bidirectional-10-epochs'\n",
    "\n",
    "# model = MyGRU(input_size=input_size, emb_size=emb_size, hidden_size=hidden_size, output_size=output_size,\n",
    "#           bidirectional=bidirectional, num_layers=num_layers).to(device)\n",
    "\n",
    "model = MyLSTM(input_size=input_size, emb_size=emb_size, hidden_size=hidden_size, output_size=output_size,\n",
    "          bidirectional=bidirectional, num_layers=num_layers).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Loop"
   ],
   "metadata": {
    "id": "Rn0c90zqIRhB"
   },
   "id": "Rn0c90zqIRhB"
  },
  {
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "\n",
    "best_f1, model_dict = 0.0, None\n",
    "\n",
    "for epoch in tqdm(range(epochs), 'Training'):\n",
    "    epoch_loss = 0\n",
    "    for Xs,Ys in train_loader:\n",
    "        Xs, Ys = Xs.to(device), Ys.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # flat the batch\n",
    "        pred_y = model.forward(Xs)\n",
    "        pred_y = pred_y.view(-1, pred_y.shape[-1])\n",
    "\n",
    "        Ys = Ys.view(-1)\n",
    "\n",
    "        loss = loss_fn(pred_y, Ys)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "    print(f'loss: {epoch_loss / len(train_loader)}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Y_pred, Y_val = [], []\n",
    "        for Xsval, Ysval in val_loader:\n",
    "            Xsval, Ysval = Xsval.to(device), Ysval.to(device)\n",
    "\n",
    "            pred_y_val = model.forward(Xsval)\n",
    "            pred_y_val = torch.argmax(pred_y_val.view(-1, pred_y_val.shape[-1]), dim=-1)\n",
    "\n",
    "            Ysval = Ysval.view(-1)\n",
    "\n",
    "            Y_pred.append([id2label[_id_.item()] for _id_ in pred_y_val])\n",
    "            Y_val.append([id2label[_id_.item()] for _id_ in Ysval])\n",
    "\n",
    "\n",
    "        f1 = f1_score(Y_val, Y_pred, average='micro')\n",
    "        print(f'f1-micro: {f1}')\n",
    "\n",
    "        if best_f1 < f1:\n",
    "            best_f1 = f1\n",
    "            model_dict = deepcopy(model.state_dict())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iV7uQgj4uuqO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750508843738,
     "user_tz": -120,
     "elapsed": 95677,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    },
    "outputId": "10f25c1a-3ff5-4d0c-93d0-9ad17e697960"
   },
   "id": "iV7uQgj4uuqO",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rTraining:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss: 0.1649706006302672\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rTraining:  10%|█         | 1/10 [00:09<01:27,  9.71s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1-micro: 0.15028901734104047\n",
      "loss: 0.0728221282489219\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rTraining:  20%|██        | 2/10 [00:19<01:17,  9.63s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1-micro: 0.4341880341880342\n",
      "loss: 0.04437654730627092\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rTraining:  30%|███       | 3/10 [00:28<01:07,  9.59s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1-micro: 0.6061643835616437\n",
      "loss: 0.0232091184973843\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rTraining:  40%|████      | 4/10 [00:38<00:57,  9.57s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1-micro: 0.605095541401274\n",
      "loss: 0.011754456110361773\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rTraining:  50%|█████     | 5/10 [00:47<00:47,  9.57s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1-micro: 0.6473429951690821\n",
      "loss: 0.004539991340252681\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rTraining:  60%|██████    | 6/10 [00:57<00:38,  9.56s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1-micro: 0.690846286701209\n",
      "loss: 0.0017989045393779495\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rTraining:  70%|███████   | 7/10 [01:07<00:28,  9.56s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1-micro: 0.6879194630872484\n",
      "loss: 0.000872275413465844\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rTraining:  80%|████████  | 8/10 [01:16<00:19,  9.55s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1-micro: 0.7247863247863249\n",
      "loss: 0.0004894064061819197\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rTraining:  90%|█████████ | 9/10 [01:26<00:09,  9.55s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1-micro: 0.6921850079744817\n",
      "loss: 0.00018888276938045144\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training: 100%|██████████| 10/10 [01:35<00:00,  9.57s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f1-micro: 0.7234782608695651\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save Model and Hyperparameters"
   ],
   "metadata": {
    "id": "BzJ2JB3x3YMu"
   },
   "id": "BzJ2JB3x3YMu"
  },
  {
   "cell_type": "code",
   "source": [
    "save_dict = {'state_dict' : model_dict,\n",
    "            'input_size': input_size,\n",
    "            'emb_size': emb_size,\n",
    "            'hidden_size': hidden_size,\n",
    "            'output_size': output_size,\n",
    "            'lr': lr,\n",
    "            'epochs': epochs,\n",
    "            'bidirectional': bidirectional,\n",
    "            'num_layers': num_layers,\n",
    "            'model_name': model_name,\n",
    "            'loss_fn': loss_fn.__class__.__name__,\n",
    "            'opt': opt.__class__.__name__}\n",
    "\n",
    "\n",
    "torch.save(save_dict, f'models/{model_name}.pt')\n"
   ],
   "metadata": {
    "id": "yeiSc_Fj3X79"
   },
   "id": "yeiSc_Fj3X79",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference\n",
    "Go to the other notebook:\n",
    "\n",
    "[rnn_sequence_labeling_inference.ipynb](rnn_sequence_labeling_inference.ipynb)"
   ],
   "metadata": {
    "id": "EhwYxtGZIWBA"
   },
   "id": "EhwYxtGZIWBA"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "3625f9035f984434"
   },
   "id": "3625f9035f984434",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
