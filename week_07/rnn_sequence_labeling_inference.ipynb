{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "authorship_tag": "ABX9TyPNv2+rCDCRTw6YYtO1+buU"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Colab"
   ],
   "metadata": {
    "id": "0HsetK6ueKwJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxx7TZaEOqH4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750508914574,
     "user_tz": -120,
     "elapsed": 19647,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    },
    "outputId": "8d5b6e11-9d87-4196-d270-115828071de6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We evaluate using seqeval"
   ],
   "metadata": {
    "id": "xeR7zA_geOMR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install seqeval"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbYFZesxOxoH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750508926076,
     "user_tz": -120,
     "elapsed": 11499,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    },
    "outputId": "4b58c776-fd56-47e8-a6ff-1f60249a2286"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/43.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.6/43.6 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (2.0.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=5c914f4f502552cf9b9649946817618b19b66838caf2f44765b624429031c4e5\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "id": "OdHeZvSjeJSK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "id": "2CdkqsXsOyrL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750508932596,
     "user_tz": -120,
     "elapsed": 6511,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We need NERDataset to load the saved DataLoaders"
   ],
   "metadata": {
    "id": "ogNVlZiKeTPO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, X, Y, vocab2id, label2id, max_seq_length):\n",
    "        self.X, self.Y = X, Y\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.vocab2id = vocab2id\n",
    "        self.label2id = label2id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens, labels = self.X[idx], self.Y[idx]\n",
    "\n",
    "        if len(tokens) > self.max_seq_length:\n",
    "            tokens = tokens[: self.max_seq_length]\n",
    "            labels = labels[: self.max_seq_length]\n",
    "        else:\n",
    "            tokens = tokens + ['<PAD>'] * (self.max_seq_length - len(tokens))\n",
    "            labels = labels + ['O'] * (self.max_seq_length - len(labels))\n",
    "\n",
    "        tokens_tensor = torch.tensor(\n",
    "            [self.vocab2id.get(token, self.vocab2id['<UNK>']) for token in tokens]).to(device)\n",
    "        labels_tensor = torch.tensor([self.label2id.get(label) for label in labels]).to(device)\n",
    "        return tokens_tensor, labels_tensor"
   ],
   "metadata": {
    "id": "DqWaRCDEP8x8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750508932607,
     "user_tz": -120,
     "elapsed": 2,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Saved Loaders"
   ],
   "metadata": {
    "id": "xJzagUOeeZ1v"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loaders = torch.load('data/loaders.pt', weights_only=False, map_location=device)\n",
    "\n",
    "train_loader = loaders['train']\n",
    "val_loader = loaders['val']\n",
    "test_loader = loaders['test']\n",
    "\n",
    "vocab2id = loaders['vocab2id']\n",
    "id2vocab = loaders['id2vocab']\n",
    "\n",
    "label2id = loaders['label2id']\n",
    "id2label = loaders['id2label']"
   ],
   "metadata": {
    "id": "DVo4q87UO2P0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750509042914,
     "user_tz": -120,
     "elapsed": 481,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### To load saved LSTM models"
   ],
   "metadata": {
    "id": "jkipxxO_ecwe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, output_size, bidirectional, num_layers):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, bidirectional=bidirectional, num_layers=num_layers, batch_first=True)\n",
    "        self.clf1 = nn.Linear(hidden_size * self.num_directions, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        e = self.embedding(X)\n",
    "        h0 = torch.zeros(self.num_directions * self.num_layers, X.shape[0], self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_directions * self.num_layers, X.shape[0], self.hidden_size).to(device)\n",
    "        o, (h0,c0) = self.lstm(e, (h0,c0))\n",
    "\n",
    "        return self.clf1(o)"
   ],
   "metadata": {
    "id": "j2AnMrqsdt5x",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750508954415,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### To load saved GRU models"
   ],
   "metadata": {
    "id": "snLK2ywaehRn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class MyGRU(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, output_size, bidirectional, num_layers):\n",
    "        super(MyGRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, bidirectional=bidirectional, num_layers=num_layers, batch_first=True)\n",
    "        self.clf1 = nn.Linear(hidden_size * self.num_directions, output_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        e = self.embedding(X)\n",
    "        h0 = torch.zeros(self.num_directions * self.num_layers, X.shape[0], self.hidden_size).to(device)\n",
    "        o, h0 = self.gru(e, h0)\n",
    "        return self.clf1(o)"
   ],
   "metadata": {
    "id": "s7MVGR08P1hp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750508957005,
     "user_tz": -120,
     "elapsed": 11,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inference"
   ],
   "metadata": {
    "id": "8RVN1RDaeq-b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "path = 'models/'\n",
    "available_models = os.listdir(path)\n",
    "\n",
    "for modelname in available_models:\n",
    "    modelpath = f'{path}/{modelname}'\n",
    "\n",
    "    loaded = torch.load(modelpath, weights_only=False, map_location=device)\n",
    "\n",
    "    if 'lstm' in modelname:\n",
    "      class_type = MyLSTM\n",
    "    else:\n",
    "      class_type = MyGRU\n",
    "\n",
    "    model_inference = class_type(input_size=loaded['input_size'], emb_size=loaded['emb_size'], hidden_size=loaded['hidden_size'], output_size=loaded['output_size'],\n",
    "              bidirectional=loaded['bidirectional'], num_layers=loaded['num_layers']).to(device)\n",
    "\n",
    "    print(model_inference.load_state_dict(loaded['state_dict']))\n",
    "\n",
    "\n",
    "    Y_pred, Y_test = [],[]\n",
    "    with torch.no_grad():\n",
    "        for Xs, Ys in tqdm(test_loader):\n",
    "            Xs, Ys = Xs.to(device), Ys.to(device)\n",
    "            pred_y = model_inference.forward(Xs)\n",
    "\n",
    "            pred_y = torch.argmax(model_inference.forward(Xs).view(-1, pred_y.shape[-1]), dim=-1)\n",
    "            Ys = Ys.view(-1)\n",
    "\n",
    "            Y_pred.append([id2label[_id_.item()] for _id_ in pred_y])\n",
    "\n",
    "            Y_test.append([id2label[_id_.item()] for _id_ in Ys])\n",
    "\n",
    "    print(f'model: {loaded[\"model_name\"]}\\n{classification_report(Y_test, Y_pred)}\\n')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8buw97k5PjUK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1750509516762,
     "user_tz": -120,
     "elapsed": 467378,
     "user": {
      "displayName": "Mario Kuzmanov",
      "userId": "06605580881605266241"
     }
    },
    "outputId": "e3d54d42-ee08-4f7f-f219-16959f8afe3a"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17/17 [00:11<00:00,  1.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model: gru-1-unidirectional-10-epochs\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  DDF       0.60      0.62      0.61       234\n",
      "  anatomical%location       0.61      0.50      0.55        22\n",
      "               animal       0.41      0.37      0.39        19\n",
      "             bacteria       0.62      0.50      0.55        84\n",
      " biomedical%technique       0.50      0.28      0.36        32\n",
      "             chemical       0.56      0.44      0.49        52\n",
      "   dietary%supplement       0.64      0.50      0.56        42\n",
      "                 drug       0.80      0.50      0.62         8\n",
      "                 food       0.00      0.00      0.00         4\n",
      "                 gene       0.00      0.00      0.00         9\n",
      "                human       0.55      0.60      0.58        85\n",
      "           microbiome       0.47      0.58      0.52        74\n",
      "statistical%technique       0.67      0.40      0.50         5\n",
      "\n",
      "            micro avg       0.57      0.53      0.55       670\n",
      "            macro avg       0.49      0.41      0.44       670\n",
      "         weighted avg       0.56      0.53      0.54       670\n",
      "\n",
      "\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17/17 [00:55<00:00,  3.28s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model: gru-2-bidirectional-10-epochs\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  DDF       0.76      0.74      0.75       234\n",
      "  anatomical%location       0.84      0.73      0.78        22\n",
      "               animal       0.75      0.47      0.58        19\n",
      "             bacteria       0.69      0.60      0.64        84\n",
      " biomedical%technique       0.43      0.28      0.34        32\n",
      "             chemical       0.52      0.56      0.54        52\n",
      "   dietary%supplement       0.84      0.64      0.73        42\n",
      "                 drug       1.00      0.38      0.55         8\n",
      "                 food       0.00      0.00      0.00         4\n",
      "                 gene       0.50      0.11      0.18         9\n",
      "                human       0.73      0.72      0.73        85\n",
      "           microbiome       0.74      0.86      0.80        74\n",
      "statistical%technique       0.43      0.60      0.50         5\n",
      "\n",
      "            micro avg       0.72      0.67      0.69       670\n",
      "            macro avg       0.63      0.51      0.55       670\n",
      "         weighted avg       0.71      0.67      0.68       670\n",
      "\n",
      "\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17/17 [00:13<00:00,  1.29it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model: lstm-1-unidirectional-10-epochs\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  DDF       0.62      0.63      0.62       234\n",
      "  anatomical%location       0.71      0.55      0.62        22\n",
      "               animal       0.23      0.16      0.19        19\n",
      "             bacteria       0.67      0.60      0.63        84\n",
      " biomedical%technique       0.35      0.19      0.24        32\n",
      "             chemical       0.55      0.40      0.47        52\n",
      "   dietary%supplement       0.63      0.45      0.53        42\n",
      "                 drug       0.80      0.50      0.62         8\n",
      "                 food       0.00      0.00      0.00         4\n",
      "                 gene       0.00      0.00      0.00         9\n",
      "                human       0.50      0.55      0.53        85\n",
      "           microbiome       0.46      0.68      0.55        74\n",
      "statistical%technique       0.25      0.20      0.22         5\n",
      "\n",
      "            micro avg       0.56      0.54      0.55       670\n",
      "            macro avg       0.44      0.38      0.40       670\n",
      "         weighted avg       0.55      0.54      0.54       670\n",
      "\n",
      "\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 17/17 [06:01<00:00, 21.24s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model: lstm-2-bidirectional-10-epochs\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "                  DDF       0.72      0.77      0.74       234\n",
      "  anatomical%location       0.67      0.73      0.70        22\n",
      "               animal       0.65      0.58      0.61        19\n",
      "             bacteria       0.71      0.71      0.71        84\n",
      " biomedical%technique       0.50      0.38      0.43        32\n",
      "             chemical       0.57      0.44      0.50        52\n",
      "   dietary%supplement       0.63      0.64      0.64        42\n",
      "                 drug       0.83      0.62      0.71         8\n",
      "                 food       0.00      0.00      0.00         4\n",
      "                 gene       0.12      0.11      0.12         9\n",
      "                human       0.74      0.75      0.74        85\n",
      "           microbiome       0.74      0.86      0.80        74\n",
      "statistical%technique       0.33      0.40      0.36         5\n",
      "\n",
      "            micro avg       0.69      0.69      0.69       670\n",
      "            macro avg       0.55      0.54      0.54       670\n",
      "         weighted avg       0.68      0.69      0.68       670\n"
     ]
    }
   ]
  }
 ]
}
